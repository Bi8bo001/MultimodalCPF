# ğŸ”® MultiCPF: A Multimodal Crystal Property Prediction Framework

MultiCPF is a modular, extensible framework for crystal property prediction via multimodal fusion of structural and textual representations. It is built upon **CrystalFormer** as the structure encoder and **MatSciBERT** for textual understanding, supporting various fusion mechanisms including sum, concat, gated, and cross-attention.

## âœ¨ Highlights

- âš™ï¸ **Modular Design**: Structure encoder, text encoder, and fusion block are independently pluggable.
- ğŸ”€ **Fusion Flexibility**: Supports `concat`, `sum`, `gated`, and `cross-attn` fusion modes.
- ğŸ§  **Interpretability**: Token-level cross-modal attention visualization and ablation tools.
- ğŸ§ª **Training Strategy**: Modality masking, data augmentation, and multitask loss supported.

## ğŸ“ Project Structure

```bash
MultiCPF/
â”‚
â”œâ”€â”€ models/                  # CrystalFormer & fusion model
â”œâ”€â”€ dataloaders/            # Dataset preparation
â”œâ”€â”€ multimodal_fusion/      # Text encoder, fusion block, loss, tools
â”œâ”€â”€ train_fusion.py         # Main training script for multimodal model
â”œâ”€â”€ utils.py                # General utilities
â”œâ”€â”€ README.md
â”œâ”€â”€ LICENSE
â””â”€â”€ download_models.sh      # ğŸ†• Script to download LLM weights
````

## ğŸš€ Quickstart

### 1. Clone & install dependencies

```bash
git clone https://github.com/Bi8bo001/MultimodalCPF.git
cd MultimodalCPF
pip install -r requirements.txt  # optional
```

### 2. Download pretrained language models

```bash
bash download_models.sh
```

### 3. Run multimodal training

```bash
bash train_fusion.sh
```

## ğŸ“œ License

This project is released under the MIT License. See [LICENSE](./LICENSE) for details.

## ğŸ™‹ Citation

Coming soon (under submission). If you use this work in your research, please consider citing us.
